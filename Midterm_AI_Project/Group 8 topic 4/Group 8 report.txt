NATIONAL
 
ECONOMICS
 
UNIVERSITY,
 
HANOI
 
COLLEGE
 
OF
 
TECHNOLOGY
 
FACULTY
 
OF
 
DATA
 
SCIENCE
 
AND
 
ARTIFICIAL
 
INTELLIGENCE
 
 
 
 
INTRODUCTION
 
TO
 
AI
 
(TOKT11121.AI66A)
 
 
 
REPORT
 
Topic:
 
Pac-Man
 
searching
 
for
 
food
 
 
 
 
 
 
 
 
Instructor:
 
Nguy·ªÖn
 
Tr·ªçng
 
Nghƒ©a
 
 
Student:
 
Nguy·ªÖn
 
Quang
 
Huy
 
‚Äì
 
11247299
 
Nguy·ªÖn
 
Tu·∫•n
 
Anh
 
-
 
11247260
 
Nguy·ªÖn
 
Xu√¢n
 
Ki·ªát
 
-
 
11247306
 
Tr·∫ßn
 
Minh
 
Ho√†ng
 
-
 
11247292
 
V≈©
 
Qu·ªëc
 
Huy
 
-
 
11247301
 
 
 
 
 
 
 
 
 
 
 
Hanoi,
 
October
 
10
 
Year
 
2025
 
 

Contents
 
1
 
Introduction
 
 
2
 
Method
 
&
 
Experiment
 
 
2.1
 
 
Problem
 
Definition
 
2.2
 
 
Method
 
a.
 
A
 
Search
 
Algorithm*
 
 
b.
 
Calculate
 
the
 
functions
 
f(n),
 
g(n),
 
h(n)
 
for
 
the
 
Pac-Man
 
problem
 
c.
 
Extending
 
A*
 
for
 
Multiple-Goal
 
Problems
 
(A*
 
for
 
Multiple
 
Goals)
 
d.
 
Obstacles
 
and
 
Their
 
Handling
 
in
 
the
 
Algorithm
 
e.
 
Technical
 
Details
 
of
 
How
 
the
 
Algorithm
 
Works
 
f.
 
Code
 
2.3
 
 
Evaluation
 
&
 
Description
 
 
3
 
Discuss
 
3.1
 
Limitations
 
of
 
the
 
Current
 
Model
 
3.2
 
Future
 
Development
 
Directions
 
 
4
 
Conclusion
 
 
 
 
1 
 
Abstract.
 
This
 
report
 
presents
 
the
 
application
 
of
 
the
 
A*
 
(A-star)
 
search
 
algorithm
 
to
 
the
 
classic
 
arcade
 
game
 
Pac-Man.
 
The
 
goal
 
is
 
to
 
simulate
 
intelligent
 
movement
 
for
 
game
 
characters
 
by
 
implementing
 
efficient
 
pathfinding
 
in
 
a
 
maze
 
environment.
 
A*
 
combines
 
actual
 
path
 
cost
 
and
 
heuristic
 
estimation
 
to
 
determine
 
the
 
optimal
 
route
 
for
 
Pac-Man
 
or
 
the
 
ghosts.
 
The
 
study
 
highlights
 
how
 
AI
 
techniques
 
can
 
enhance
 
gameplay
 
by
 
improving
 
responsiveness
 
and
 
strategic
 
behavior .
 
Experimental
 
results
 
and
 
analysis
 
demonstrate
 
that
 
A*
 
provides
 
an
 
effective
 
balance
 
between
 
optimality
 
and
 
computational
 
efficiency ,
 
making
 
it
 
a
 
suitable
 
choice
 
for
 
real-time
 
game
 
AI.
 
Keywords:
 
Artificial
 
Intelligence
 
¬∑
 
Pathfinding
 
¬∑
 
A*
 
Algorithm
 
¬∑
 
Pac-Man
 
¬∑
 
Game
 
Development
 
1
 
Introduction
 
Pac-Man,
 
released
 
in
 
1980,
 
is
 
one
 
of
 
the
 
most
 
iconic
 
arcade
 
games
 
in
 
history.
 
The
 
player
 
controls
 
Pac-Man
 
to
 
navigate
 
a
 
maze,
 
eat
 
pellets,
 
and
 
avoid
 
four
 
chasing
 
ghosts.
 
Although
 
the
 
gameplay
 
rules
 
are
 
simple,
 
Pac-Man
 
requires
 
quick
 
decision-making
 
and
 
strategic
 
movement
 
to
 
succeed.
 
Artificial
 
Intelligence
 
(AI)
 
plays
 
a
 
vital
 
role
 
in
 
creating
 
engaging
 
gameplay
 
experiences.
 
In
 
Pac-Man,
 
AI
 
determines
 
the
 
behavior
 
of
 
the
 
ghosts,
 
directly
 
influencing
 
the
 
game‚Äôs
 
difficulty
 
and
 
excitement.
 
A
 
well-designed
 
AI
 
system
 
ensures
 
that
 
the
 
game
 
remains
 
both
 
challenging
 
and
 
enjoyable.
  
 
The
 
A*
 
(A-star)
 
algorithm
 
is
 
chosen
 
for
 
this
 
study
 
due
 
to
 
its
 
efficiency
 
and
 
ability
 
to
 
find
 
optimal
 
paths.
 
A*
 
uses
 
an
 
evaluation
 
function
 
f(n)=g(n)+h(n)
 
to
 
balance
 
the
 
actual
 
cost
 
and
 
the
 
estimated
 
cost
 
to
 
the
 
goal.
 
Its
 
speed
 
and
 
accuracy
 
make
 
it
 
suitable
 
for
 
controlling
 
the
 
movement
 
of
 
Pac-Man
 
or
 
the
 
ghosts
 
within
 
the
 
maze.
    
 
We
 
also
 
use
 
the
 
BFS
 
algorithm
 
to
 
make
 
a
 
comparison
 
between
 
the
 
two
 
algorithms
 
in
 
the
 
next
 
section.
 
The
 
BFS
 
(Breadth-First
 
Search)
 
algorithm
 
traverses
 
the
 
graph
 
in
 
a
 
breadth-first
 
manner,
 
meaning
 
that
 
starting
 
from
 
a
 
source
 
vertex,
 
it
 
visits
 
all
 
neighboring
 
vertices
 
of
 
that
 
vertex
 
first,
 
before
 
moving
 
on
 
to
 
the
 
vertices
 
in
 
the
 
next
 
layer.
 
BFS
 
uses
 
a
 
queue
 
to
 
manage
 
the
 
traversal
 
order,
 
ensuring
 
that
 
vertices
 
are
 
visited
 
in
 
increasing
 
order
 
of
 
distance
 
from
 
the
 
starting
 
vertex.
 
Thanks
 
to
 
this,
 
in
 
an
 
unweighted
 
graph,
 
BFS
 
can
 
find
 
the
 
2
 
 
shortest
 
path
 
from
 
the
 
starting
 
vertex
 
to
 
every
 
other
 
vertex.
 
 
2
 
Method
 
&
 
Experiment
 
2.1
 
Problem
 
Definition
 
Pac-Man
 
needs
 
to
 
move
 
in
 
a
 
5x5
 
grid
 
to
 
eat
 
all
 
the
 
‚Äúdots‚Äù
 
(food
 
pellets).
 
Goal:
 
Find
 
the
 
shortest
 
path
 
that
 
allows
 
Pac-Man
 
to
 
collect
 
all
 
the
 
dots
 
with
 
the
 
minimum
 
movement
 
cost.
 
The
 
environment
 
includes:
 
‚óè
 
Empty
 
cells
 
(Pac-Man
 
can
 
move
 
through
 
them)
 
‚óè
 
Pac-Man‚Äôs
 
starting
 
position
 
‚óè
 
Dots
 
to
 
be
 
collected
 
‚óè
 
Obstacles
 
(#)
 
that
 
Pac-Man
 
cannot
 
pass
 
through
 
‚óè
 
Movement
 
directions:
 
Up/Down/Right/Left
 
(no
 
diagonal
 
moves
 
allowed)
 
‚óè
 
Each
 
step
 
has
 
a
 
cost
 
=
 
1
 
 
 
2.2
 
Method
 
a.
 
A
 
Search
 
Algorithm*
 
 
Goal:
 
Find
 
the
 
shortest
 
path
 
that
 
allows
 
Pac-Man
 
to
 
collect
 
all
 
the
 
dots
 
with
 
the
 
minimum
 
movement
 
cost.
 
Initial
 
State
 
The
 
Initial
 
State
 
 
is
 
defined
 
as
 
a
 
triplet:
 ùë†
0
‚óè
 
LaTeX
 
Code:
 
 ùë†
0=ùë•
ùë†ùë°ùëéùëüùë°,ùë¶
ùë†ùë°ùëéùëüùë°,ùëÜ
ùëéùëôùëô
(
)
o
 
:
 
The
 
starting
 
coordinates
 
of
 
Pac-Man
 
on
 
the
 ùë•
ùë†ùë°ùëéùëüùë°,ùë¶
ùë†ùë°ùëéùëüùë°
(
)
 
grid.
 5 √ó5
o
 
:
 
The
 
set
 
of
 
coordinates
 
 
for
 
all
 
the
 
initial
 
"dots"
 ùëÜ
ùëéùëôùëôùë•
ùëñ,ùë¶
ùëñ
(
)
(food
 
pellets)
 
present
 
on
 
the
 
grid.
 
State
 
Any
 
State
 
 
is
 
defined
 
as
 
the
 
triplet:
 ùë† 
3
 
 
‚óè
 
LaTeX
 
Code:
 
 ùë†=ùë•,ùë¶,ùëÜ
ùëëùëúùë°ùë†
(
)
o
 
 
The
 
current
 
coordinates
 
(position)
 
of
 
Pac-Man.
 ùë•,ùë¶():
o
 
:
 
The
 
set
 
of
 
coordinates
 
of
 
the
 
uncollected
 
dots
 ùëÜ
ùëëùëúùë°ùë†
remaining
 
in
 
the
 
environment.
 
Operators/Actions
 
The
 
Set
 
of
 
Operators
 
 
includes
 
4
 
basic
 
movement
 
directions:
 ùê¥
‚óè
 
LaTeX
 
Code:
 
 ùê¥={ùëàùëù, ùê∑ùëúùë§ùëõ, ùêøùëíùëìùë°, ùëÖùëñùëî‚Ñéùë°}
Validity
 
An
 
action
 
 
at
 
state
 
 
is
 
valid
 
if
 
and
 
only
 
if
 
the
 ùëé‚ààùê¥ùë†=ùë•,ùë¶,ùëÜ
ùëëùëúùë°ùë†
(
)
resulting
 
new
 
position
 
$(x',
 
y')$
 
satisfies
 
both
 
conditions:
 
1.
 
The
 
position
 
 
is
 
not
 
an
 
obstacle
 
 
ùë•'
,
ùë¶'
(
)()
2.
 
The
 
position
 
 
is
 
within
 
the
 
boundaries
 
of
 
the
 
 
grid.
 
ùë•'
,
ùë¶'
(
)5 √ó5
State
 
Transition
 
‚óè
 
The
 
Successor
 
State
 
ùë†'
ùëñùë†
ùë•'
,
ùë¶'
,
ùëÜ
ùëëùëúùë°ùë†'
(
).
‚óè
 
 
is
 
a
 
dot;
 
otherwise,
 
 
ùëÜ
ùëëùëúùë°ùë†'
=
ùëÜ
ùëëùëúùë°ùë†
‚àñ
{
ùë•'
,
ùë¶'
(
)
ùëñùëì
ùë•'
,
ùë¶'
(
)
ùëÜ
ùëëùëúùë°ùë†'
=
ùëÜ
ùëëùëúùë°ùë†
.
Cost
 
The
 
Cost
 
 
for
 
each
 
movement
 
step:
 
ùê∂
ùë†
,
ùëé
,
ùë†'
(
)
‚óè
 
LaTeX
 
Code:
 
 
ùê∂
ùë†
,
ùëé
,
ùë†'
(
)=1
‚óè
 
Objective:
 
Find
 
the
 
path
 
 
that
 
minimizes
 
the
 
total
 
cost
.
 ùëÉ
Goal
 
Test
 
A
 
state
 
is
 
a
 
Goal
 
State
 
if:
 ùë† 
‚óè
 
LaTeX
 
Code:
 
 
0
 ùê∫ùëúùëéùëô ùëáùëíùë†ùë°ùë†()‚áîùëÜ
ùëëùëúùë°ùë†=
4
 
 
‚óè
 
This
 
means
 
Pac-Man
 
has
 
collected
 
all
 
the
 
"dots"
 
on
 
the
 
grid.
 
Example
 
of
 
A*:
 
Task:
 
Find
 
the
 
optimal
 
route
 
from
 
position
 
A
 
(start)
 
‚Üí
 
position
 
C
 
(goal).
 
 
Step
 
0
 
‚Äî
 
Initialization
 
‚óè
 
g(A)
 
=
 
0,
 
h(A)
 
=
 
4
 
‚Üí
 
f(A)
 
=
 
4
 
‚óè
 
Others:
 
g
 
=
 
‚àû
 
 
Node
 
 
g
 
 
h
 
f
 
=
 
g
 
+
 
h
 
Prev
 
A
 
0
 
4
 
‚àû
 
-
 
B
 
‚àû
 
2
 
‚àû
 
-
 
C
 
‚àû
 
0
 
‚àû
 
-
 
D
 
‚àû
 
4
 
‚àû
 
-
 
E
 
‚àû
 
2
 
‚àû
 
-
 
 
Open
 
=
 
{A(f=4)}
 
Closed
 
=
 
‚àÖ
 
Step
 
1
 
‚Äî
 
Expand
 
A
 
From
 
A
 
‚Üí
 
B
 
(5),
 
D
 
(7)
 
‚óè
 
B:
 
g(B)
 
=
 
0
 
+
 
5
 
=
 
5
 
‚Üí
 
f(B)
 
=
 
5
 
+
 
2
 
=
 
7
,
 
Prev(B)=A
 
5
 

 
‚óè
 
D:
 
g(D)
 
=
 
0
 
+
 
7
 
=
 
7
 
‚Üí
 
f(D)
 
=
 
7
 
+
 
4
 
=
 
11
,
 
Prev(D)=A
 
Mark
 
A
 
as
 
closed.
 
 
Node
 
 
g
 
 
h
 
f
 
=
 
g
 
+
 
h
 
Prev
 
A
 
0
 
4
 
4
 
-
 
(Closed)
 
B
 
5
 
2
 
7
 
A
 
C
 
‚àû
 
0
 
‚àû
 
-
 
D
 
7
 
4
 
11
 
A
 
E
 
‚àû
 
2
 
‚àû
 
-
 
 
Open
 
=
 
{B(7),
 
D(11)}
 
Closed
 
=
 
{A}
 
 
Step
 
2
 
‚Äî
 
Expand
 
B
 
(lowest
 
f
 
=
 
7)
 
From
 
B
 
‚Üí
 
C
 
(4):
 
‚óè
 
C:
 
g(C)
 
=
 
5
 
+
 
4
 
=
 
9
 
‚Üí
 
f(C)
 
=
 
9
 
+
 
0
 
=
 
9
,
 
Prev(C)=B
 
Mark
 
B
 
as
 
closed.
 
 
Node
 
 
g
 
 
h
 
f
 
=
 
g
 
+
 
h
 
Prev
 
A
 
0
 
4
 
4
 
 
-
 
B
 
5
 
2
 
7
 
A
 
C
 
9
 
0
 
9
 
B
 
D
 
7
 
4
 
11
 
A
 
E
 
‚àû
 
2
 
‚àû
 
-
 
 
Open
 
=
 
{C(9),
 
D(11)}
 
Closed
 
=
 
{A,
 
B}
 
 
6
 
 
Step
 
3
 
‚Äî
 
Expand
 
C
 
(lowest
 
f
 
=
 
9)
 
C
 
is
 
the
 
goal
,
 
so
 
we
 
stop
 
here.
 
Final
 
table:
 
 
Node
 
 
g
 
 
h
 
f
 
=
 
g
 
+
 
h
 
Prev
 
A
 
0
 
4
 
4
 
 
-
 
B
 
5
 
2
 
7
 
A
 
C
 
9
 
0
 
9
 
B
 
D
 
7
 
4
 
11
 
A
 
E
 
‚àû
 
2
 
‚àû
 
-
 
 
4)
 
Result
 
‚úÖ
 
Shortest
 
path
 
found
 
by
 
A*
:
 
A
 
‚Üí
 
B
 
‚Üí
 
C
 
‚úÖ
 
Total
 
cost
:
 
g(C)
 
=
 
9
 
(AB
 
=
 
5,
 
BC
 
=
 
4)
 
 
b.
 
Calculate
 
the
 
functions
 
f(n),
 
g(n),
 
h(n)
 
for
 
the
 
Pac-Man
 
problem
 
g(n):
 
The
 
actual
 
cost
 
from
 
the
 
start
 
position
 
‚Üí
 
current
 
cell
 
‚Üí
 
Each
 
move
 
has
 
cost
 
=
 
1
 
‚Üí
 
Example:
 
(0,0)
 
‚Üí
 
(1,0)
 
‚áí
 
g
 
=
 
1
 
h(n):
 
The
 
estimated
 
remaining
 
cost
 
to
 
the
 
Dot
 
‚Üí
 
Use
 
Manhattan
 
distance:
 
 ‚Ñé=‚à£ùë•1 ‚àíùë•2 ‚à£+‚à£ùë¶1 ‚àíùë¶2 ‚à£ 
‚Üí
 
Heuristic
 
admissible
 
(does
 
not
 
exceed
 
the
 
actual
 
cost)
 
f(n)
 
=
 
g(n)
 
+
 
h(n):
 
‚Üí
 
Total
 
estimated
 
cost
 
‚Üí
 
A*
 
always
 
expands
 
the
 
node
 
with
 
the
 
smallest
 
f
 
Ô¨Årst
 
7
 
 
Example:
 
Pac-Man
 
at
 
(1,0),
 
Dot
 
at
 
(2,3):
 
‚Üí
 
g
 
=
 
1,
 
h
 
=
 
4
 
‚áí
 
f
 
=
 
5
 
c.
 
Extending
 
A*
 
for
 
Multiple-Goal
 
Problems
 
(A*
 
for
 
Multiple
 
Goals)
 
 
 
Method
 
1:
 
Brute
 
Force
 
/
 
Dynamic
 
Programming
 
‚óè
 
Explore
 
all
 
possible
 
orders
 
of
 
visiting
 
the
 
Dots
 
(permutations).
 
‚óè
 
Use
 
A*
 
or
 
BFS/UCS
 
to
 
calculate
 
the
 
total
 
cost
 
of
 
each
 
route.
 
‚óè
 
Choose
 
the
 
shortest
 
route
 
‚Üí
 
absolutely
 
optimal
 
result.
 
‚óè
 
Drawback:
 
Complexity
 
O(m!)O(m!)O(m!),
 
only
 
suitable
 
for
 
a
 
small
 
number
 
of
 
Dots
 
(such
 
as
 
in
 
a
 
5x5
 
grid).
 
Method
 
2:
 
Extended
 
A*
 
‚óè
 
State
 
=
 
(Pac-Man‚Äôs
 
position,
 
Set
 
of
 
remaining
 
Dots).
 
‚óè
 
When
 
Pac-Man
 
eats
 
a
 
Dot
 
‚Üí
 
remove
 
that
 
Dot
 
from
 
the
 
remaining
 
set.
 
‚óè
 
Goal:
 
The
 
remaining
 
set
 
of
 
Dots
 
is
 
empty
 
(all
 
eaten).
 
‚óè
 
A*
 
searches
 
for
 
the
 
optimal
 
path
 
in
 
the
 
expanded
 
state
 
space.
 
‚óè
 
A
 
suitable
 
heuristic
 
function
 
needs
 
to
 
be
 
designed
 
for
 
multiple
 
goals.
 
d.
 
Obstacles
 
and
 
Their
 
Handling
 
in
 
the
 
Algorithm
 
Pac-Man
 
cannot
 
move
 
through
 
wall
 
cells
 
‚Üí
 
this
 
limits
 
the
 
state
 
space.
 
When
 
expanding
 
moves,
 
ignore
 
cells
 
that
 
are:
 
‚óè
 
Outside
 
the
 
map
 
‚óè
 
Walls
 
(no
 
valid
 
neighbors)
 
Walls
 
make
 
the
 
actual
 
path
 
longer,
 
but
 
the
 
Manhattan
 
heuristic
 
is
 
still
 
admissible
 
(does
 
not
 
underestimate
 
the
 
cost).
 
If
 
a
 
Dot
 
is
 
completely
 
surrounded
 
by
 
walls,
 
A*
 
cannot
 
reach
 
the
 
goal
 
state
 
‚Üí
 
the
 
algorithm
 
concludes
 
failure.
 
8
 
 
It
 
is
 
necessary
 
to
 
handle
 
and
 
report
 
an
 
error
 
when
 
it
 
is
 
impossible
 
to
 
collect
 
all
 
the
 
Dots.
 
e.
 
Technical
 
Details
 
of
 
How
 
the
 
Algorithm
 
Works
 
Initialization
 
‚óè
 
Put
 
the
 
initial
 
state
 
into
 
the
 
Open
 
list
 
(g=0,f=g+h)(g
 
=
 
0,
 
f
 
=
 
g
 
+
 
h)(g=0,f=g+h).
 
Loop
 
‚óè
 
Take
 
the
 
state
 
with
 
the
 
smallest
 
fff
 
from
 
Open.
 
‚óè
 
If
 
all
 
Dots
 
have
 
been
 
eaten
 
‚Üí
  
Success.
 
‚óè
 
Otherwise:
 
expand
 
valid
 
neighboring
 
cells
 
(4
 
directions).
 
o
 
Ignore
 
walls
 
/
 
out-of-bound
 
cells.
 
o
 
If
 
moving
 
into
 
a
 
cell
 
with
 
a
 
Dot
 
‚Üí
 
update
 
the
 
set
 
of
 
remaining
 
Dots.
 
o
 
Recalculate
 
g,h,fg,
 
h,
 
fg,h,f
 
and
 
update
 
into
 
the
 
Open
 
list.
 
Termination
 
‚óè
 
If
 
Open
 
is
 
empty
 
‚Üí
 
‚ùå
 
No
 
valid
 
path
 
exists.
 
 
f.
 
Code
 
 
 
import
 
matplotlib.pyplot
 
as
 
plt
 
from
 
matplotlib.patches
 
import
 
Circle,
 
Wedge,
 
Rectangle,
 
FancyArrowPatch
 
import
 
numpy
 
as
 
np
 
 
def
 
draw_map_with_path_and_result(path,
 
walls,
 
pacman_pos,
 
goals):
 
    
n
 
=
 
5
 
    
fig,
 
ax
 
=
 
plt.subplots(figsize=(5,
 
5))
 
    
ax.set_xlim(0,
 
n)
 
    
ax.set_ylim(0,
 
n)
 
9
 
 
    
ax.set_aspect('equal')
 
    
ax.set_facecolor('#dfe6e9')
 
 
    
#
 
---
 
Draw
 
grid
 
background
 
---
 
    
for
 
i
 
in
 
range(n):
 
        
for
 
j
 
in
 
range(n):
 
            
rect
 
=
 
Rectangle((j,
 
i),
 
1,
 
1,
 
                             
edgecolor='white',
 
                             
facecolor='#b2bec3',
 
                             
linewidth=2)
 
            
ax.add_patch(rect)
 
 
    
#
 
---
 
Draw
 
walls
 
---
 
    
for
 
(r,
 
c)
 
in
 
walls:
 
        
ax.text(c
 
+
 
0.5,
 
n
 
-
 
r
 
-
 
0.5,
 
'
‚úï
',
 
fontsize=45,
 
                
color='#2d3436',
 
ha='center',
 
va='center',
 
weight='bold')
 
 
    
#
 
---
 
Path
 
with
 
gradient
 
colors
 
---
 
    
colors
 
=
 
plt.cm.plasma(np.linspace(0,
 
1,
 
len(path)))
 
 
    
for
 
i
 
in
 
range(len(path)
 
-
 
1):
 
        
(r1,
 
c1),
 
(r2,
 
c2)
 
=
 
path[i],
 
path[i
 
+
 
1]
 
        
y1,
 
x1
 
=
 
n
 
-
 
r1
 
-
 
0.5,
 
c1
 
+
 
0.5
 
        
y2,
 
x2
 
=
 
n
 
-
 
r2
 
-
 
0.5,
 
c2
 
+
 
0.5
 
        
arrow
 
=
 
FancyArrowPatch((x1,
 
y1),
 
(x2,
 
y2),
 
                                
color=colors[i],
 
                                
arrowstyle='-|>',
 
                                
mutation_scale=18,
 
                                
linewidth=3)
 
        
ax.add_patch(arrow)
 
 
    
#
 
---
 
Pac-Man
 
---
 
    
pac_x,
 
pac_y
 
=
 
pacman_pos
 
    
pacman
 
=
 
Wedge(center=(pac_y
 
+
 
0.5,
 
n
 
-
 
pac_x
 
-
 
0.5),
 
                   
r=0.35,
 
theta1=30,
 
theta2=330,
 
                   
facecolor='#f1c40f',
 
edgecolor='none')
 
    
ax.add_patch(pacman)
 
 
10
 
 
    
#
 
---
 
Dots
 
(goals)
 
---
 
    
for
 
(gx,
 
gy)
 
in
 
goals:
 
        
dot
 
=
 
Circle((gy
 
+
 
0.5,
 
n
 
-
 
gx
 
-
 
0.5),
 
                     
0.25,
 
facecolor='#f1c40f',
 
edgecolor='none')
 
        
ax.add_patch(dot)
 
 
    
ax.axis('of f')
 
    
plt.tight_layout()
 
    
plt.show()
 
 
    
#
 
---
 
Print
 
results
 
---
 
    
print("===
 
PATH
 
RESUL T
 
===")
 
    
print(f"
 
Total
 
steps:
 
{len(path)
 
-
 
1}")
 
    
print(f"
 
Coordinates
 
along
 
the
 
path:")
 
    
for
 
step,
 
pos
 
in
 
enumerate(path):
 
        
print(f"
   
Step
 
{step:>2}:
 
{pos}")
 
 
    
#
 
Check
 
which
 
dots
 
were
 
eaten
 
    
eaten_dots
 
=
 
[dot
 
for
 
dot
 
in
 
goals
 
if
 
dot
 
in
 
path]
 
    
print(f"
 
Dots
 
eaten:
 
{eaten_dots
 
if
 
eaten_dots
 
else
 
'No
 
dots
 
eaten
 
üòÖ
'}")
 
 
 
#
 
---
 
Map
 
configuration
 
---
 
walls
 
=
 
[(1,
 
1),
 
(2,
 
1),
 
(3,
 
1)]
 
pacman_pos
 
=
 
(0,
 
0)
 
goals
 
=
 
[(0,
 
4),
 
(4,
 
4)]
 
 
#
 
---
 
Example
 
path
 
(Pac-Man
 
moves
 
right
 
then
 
down)
 
---
 
path
 
=
 
[
 
    
(0,
 
0),
 
(0,
 
1),
 
(0,
 
2),
 
(0,
 
3),
 
(0,
 
4),
 
    
(1,
 
4),
 
(2,
 
4),
 
(3,
 
4),
 
(4,
 
4)
 
]
 
 
#
 
---
 
Run
 
function
 
---
 
draw_map_with_path_and_result(path,
 
walls,
 
pacman_pos,
 
goals)
 
 
 
   
     
 
11
 
 
I.
 
Simple
 
path
 
 
===
 
PATH
 
RESULT
 
===
 
Total
 
steps:
 
8
 
Coordinates
 
along
 
the
 
path:
 
   
Step
  
0:
 
(0,
 
0)
 
   
Step
  
1:
 
(0,
 
1)
 
   
Step
  
2:
 
(0,
 
2)
 
   
Step
  
3:
 
(0,
 
3)
 
   
Step
  
4:
 
(0,
 
4)
 
   
Step
  
5:
 
(1,
 
4)
 
   
Step
  
6:
 
(2,
 
4)
 
   
Step
  
7:
 
(3,
 
4)
 
12
 

 
   
Step
  
8:
 
(4,
 
4)
 
 
Dots
 
eaten:
 
[(0,
 
4),
 
(4,
 
4)]
 
II.
 
Complicate
 
 
FOUND
 
PATH:
 
[(0,
 
0),
 
(0,
 
1),
 
(1,
 
1),
 
(2,
 
1),
 
(2,
 
0),
 
(3,
 
0),
 
(4,
 
0),
 
(3,
 
0),
 
(2,
 
0),
 
(2,
 
1),
 
(2,
 
2),
 
(2,
 
3),
 
(1,
 
3),
 
(0,
 
3),
 
(0,
 
4)]
 
Total
 
steps:
 
14
 
 
Explanation
 
pseudocode:
 
-
 
The
 
variable
 
start_position
 
represents
 
Pacman‚Äôs
 
starting
 
coordinate
 
(for
 
example
 
(0,
 
0)
),
 
and
 
goal_set
 
is
 
the
 
set
 
of
 
coordinates
 
containing
 
the
 
dots
 
that
 
Pacman
 
must
 
eat.
 
13
 

 
-
 
The
 
state
 
structure
 
consists
 
of
 
two
 
parts:
 
 
(current_pos,
 
remainingGoals)
,
 
where
 
current_pos
 
is
 
Pacman‚Äôs
 
current
 
location
 
and
 
remainingGoals
 
is
 
the
 
set
 
of
 
dots
 
that
 
have
 
not
 
yet
 
been
 
eaten.
 
-
 
Open
 
is
 
a
 
priority
 
queue
 
that
 
stores
 
states
 
along
 
with
 
their
 
corresponding
 
f-values
.
 
 
Closed
 
is
 
the
 
set
 
of
 
states
 
already
 
processed
.
 
-
 
The
 
heuristic(state)
 
function
 
can
 
be
 
customized.
 
 
In
 
this
 
example,
 
it
 
uses
 
the
 
sum
 
of
 
Manhattan
 
distances
 
from
 
the
 
current
 
position
 
to
 
all
 
remaining
 
goals.
 
 
(This
 
is
 
just
 
a
 
simple
 
example;
 
in
 
practice,
 
you
 
would
 
replace
 
it
 
with
 
Tu·∫•n
 
Anh‚Äôs
 
improved
 
heuristic
 
for
 
better
 
performance.)
 
-
 
The
 
algorithm
 
repeatedly
 
extracts
 
the
 
best
 
state
 
(
current_state
)
 
from
 
the
 
Open
 
list
 
‚Äî
 
the
 
one
 
with
 
the
 
smallest
 
f
 
value.
 
 
If
 
that
 
state
 
has
 
already
 
been
 
processed,
 
it
 
is
 
skipped
 
(the
 
loop
 
continues
 
to
 
the
 
next
 
state).
 
 
If
 
not,
 
the
 
state
 
is
 
added
 
to
 
Closed
.
 
 
Then,
 
the
 
algorithm
 
checks
 
whether
 
all
 
goals
 
have
 
been
 
eaten
 
(i.e.,
 
remainingGoals
 
is
 
empty).
 
 
If
 
so,
 
the
 
search
 
terminates
 
successfully.
 
-
 
If
 
the
 
goal
 
has
 
not
 
yet
 
been
 
reached,
 
the
 
algorithm
 
explores
 
all
 
valid
 
neighboring
 
cells
 
(not
 
walls
 
and
 
within
 
the
 
grid
 
boundaries).
 
 
For
 
each
 
valid
 
neighbor,
 
it
 
creates
 
a
 
new
 
state
 
(
new_state
)
.
 
 
If
 
the
 
neighbor‚Äôs
 
position
 
contains
 
a
 
dot
 
that
 
is
 
still
 
in
 
the
 
goal
 
set,
 
that
 
dot
 
is
 
removed
 
from
 
remainingGoals
 
because
 
Pacman
 
eats
 
it
 
upon
 
arrival.
 
 
The
 
tentative
 
cost
 
g
 
to
 
reach
 
this
 
new
 
state
 
equals
 
the
 
current
 
cost
 
plus
 
one
 
step
 
(
g[current]
 
+
 
1
).
 
-
 
If
 
the
 
new
 
state
 
has
 
not
 
been
 
visited
 
before,
 
or
 
if
 
a
 
shorter
 
path
 
to
 
it
 
is
 
found,
 
the
 
algorithm
 
updates:
 
‚óè
 
g[new_state]
,
 
 
‚óè
 
recomputes
 
the
 
heuristic
 
h[new_state]
,
 
 
‚óè
 
updates
 
f[new_state]
 
=
 
g
 
+
 
h
,
 
 
‚óè
 
stores
 
its
 
parent
 
for
 
path
 
reconstruction,
 
 
14
 
 
‚óè
 
and
 
pushes
 
it
 
into
 
the
 
Open
 
list
.
 
 
-
 
This
 
process
 
repeats
 
until
 
the
 
Open
 
list
 
becomes
 
empty
 
(no
 
more
 
paths)
 
or
 
the
 
goal
 
condition
 
is
 
met
 
(all
 
dots
 
eaten).
 
 
 
 
-
 
Goal
 
Pacman
 
must
 
eat
 
both
 
D1
 
and
 
D2
 
using
 
the
 
shortest
 
possible
 
path
.
 
 
We‚Äôll
 
trace
 
the
 
operation
 
of
 
the
 
A*
 
algorithm
 
step
 
by
 
step
 
using
 
the
 
simple
 
Manhattan
 
heuristic
 
(in
 
this
 
case,
 
the
 
sum
 
of
 
Manhattan
 
distances
 
to
 
all
 
remaining
 
dots
 
at
 
each
 
state).
 
 
Step
 
0
 
‚Äì
 
Initialization
 
15
 

 
 
‚óè
 
Start
 
state:
 
Pacman
 
at
 
(0,0)
,
 
goal
 
set
 
=
 
{(0,4),
 
(4,4)}
.
 
 
‚óè
 
Compute
 
g(start)
 
=
 
0
.
 
 
‚óè
 
Manhattan
 
distance
 
to
 
D1
 
=
 
4
 
(difference
 
of
 
4
 
columns).
 
 
‚óè
 
Manhattan
 
distance
 
to
 
D2
 
=
 
8
 
(difference
 
of
 
4
 
rows
 
+
 
4
 
columns).
 
 
‚óè
 
Using
 
the
 
sum
 
of
 
Manhattan
 
distances
,
 
 
h(start)
 
=
 
4
 
+
 
8
 
=
 
12
.
 
 
‚óè
 
So,
 
f(start)
 
=
 
0
 
+
 
12
 
=
 
12
.
 
 
Open
 
list:
 
{(0,0;
 
{D1,
 
D2})
 
with
 
f=12}
 
 
Closed
 
set:
 
empty.
 
 
 
Step
 
1
 
16
 

 
 
Take
 
the
 
state
 
with
 
the
 
smallest
 
f
 
from
 
Open
:
 
 
‚Üí
 
(0,0;
 
{D1,
 
D2})
 
(f
 
=
 
12).
 
 
Move
 
it
 
to
 
Closed
.
 
 
Open
 
is
 
temporarily
 
empty.
 
Expand
 
neighbors
 
of
 
(0,0)
:
 
‚óè
 
Valid
 
neighbors:
 
(0,1)
 
(right)
 
and
 
(1,0)
 
(down).
 
 
(Up
 
and
 
left
 
do
 
not
 
exist;
 
both
 
cells
 
are
 
free,
 
not
 
walls.)
 
 
Neighbor
 
(0,1)
:
 
‚óè
 
Still
 
{D1,
 
D2}
 
(no
 
dot
 
eaten).
 
 
‚óè
 
g
 
=
 
1
.
 
 
‚óè
 
h
 
=
 
Manhattan((0,1),
 
D1)
 
+
 
Manhattan((0,1),
 
D2)
 
 
=
 
3
 
+
 
7
 
=
 
10.
 
 
‚óè
 
f
 
=
 
1
 
+
 
10
 
=
 
11
.
 
 
Neighbor
 
(1,0)
:
 
17
 

 
‚óè
 
Still
 
{D1,
 
D2}
.
 
 
‚óè
 
g
 
=
 
1
.
 
 
‚óè
 
h
 
=
 
Manhattan((1,0),
 
D1)
 
+
 
Manhattan((1,0),
 
D2)
 
 
=
 
5
 
+
 
7
 
=
 
12.
 
 
‚óè
 
f
 
=
 
1
 
+
 
12
 
=
 
13
.
 
 
Add
 
new
 
states
 
to
 
Open
:
 
 
‚Üí
 
{(0,1;
 
{D1,
 
D2}):
 
f=11,
 
(1,0;
 
{D1,
 
D2}):
 
f=13}
 
 
Store
 
parents
 
accordingly.
 
 
 
Step
 
2
 
 
Pick
 
the
 
smallest
 
f
:
 
(0,1;
 
{D1,
 
D2})
 
(f=11).
 
 
Move
 
it
 
to
 
Closed
.
 
 
Open
 
now
 
=
 
{(1,0):
 
f=13}
.
 
18
 

 
Expand
 
neighbors
 
of
 
(0,1)
:
 
‚óè
 
Possible:
 
(0,0)
 
(left,
 
already
 
Closed),
 
(0,2)
 
(right),
 
(1,1)
 
(down).
 
 
Ignore
 
(0,0)
.
 
 
Neighbor
 
(0,2)
:
 
g
 
=
 
2
.
 
 
h
 
=
 
Manhattan((0,2),
 
D1)
 
+
 
Manhattan((0,2),
 
D2)
 
 
=
 
2
 
+
 
6
 
=
 
8.
 
 
f
 
=
 
2
 
+
 
8
 
=
 
10
.
 
 
Neighbor
 
(1,1)
:
 
‚óè
 
g
 
=
 
2
.
 
 
‚óè
 
h
 
=
 
Manhattan((1,1),
 
D1)
 
+
 
Manhattan((1,1),
 
D2)
 
 
=
 
4
 
+
 
6
 
=
 
10.
 
 
‚óè
 
f
 
=
 
2
 
+
 
10
 
=
 
12
.
 
 
Open:
 
{(0,2):
 
f=10,
 
(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
Step
 
3
 
19
 
 
 
Pick
 
(0,2;
 
{D1,
 
D2})
 
(f=10).
 
 
Move
 
to
 
Closed
.
 
 
Open
 
=
 
{(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
Expand
 
(0,2)
:
 
‚óè
 
Neighbors:
 
(0,1)
 
(Closed),
 
(0,3)
 
(right),
 
(1,2)
 
(down).
 
 
(1,2)
 
is
 
a
 
wall
 
‚Üí
 
skip.
 
 
Neighbor
 
(0,3)
:
 
‚óè
 
g
 
=
 
3
.
 
 
‚óè
 
h
 
=
 
Manhattan((0,3),
 
D1)
 
+
 
Manhattan((0,3),
 
D2)
 
 
=
 
1
 
+
 
5
 
=
 
6.
 
 
‚óè
 
f
 
=
 
3
 
+
 
6
 
=
 
9
.
 
 
Open:
 
{(0,3):
 
f=9,
 
(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
 
20
 

 
Step
 
4
 
 
Pick
 
(0,3;
 
{D1,
 
D2})
 
(f=9).
 
 
Move
 
to
 
Closed
.
 
 
Open
 
=
 
{(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
Expand
 
(0,3)
:
 
‚óè
 
Neighbors:
 
(0,2)
 
(Closed),
 
(0,4)
 
(right),
 
(1,3)
 
(down).
 
 
Neighbor
 
(0,4)
:
 
‚óè
 
This
 
is
 
Dot
 
D1
.
 
 
‚óè
 
Pacman
 
eats
 
D1
 
‚Üí
 
new
 
remaining
 
goals
 
{(4,4)}
.
 
 
‚óè
 
g
 
=
 
4
.
 
 
‚óè
 
h
 
=
 
Manhattan((0,4),
 
D2)
 
=
 
4.
 
 
21
 

 
‚óè
 
f
 
=
 
4
 
+
 
4
 
=
 
8
.
 
 
‚Üí
 
(0,4;
 
{D2})
 
(D1
 
eaten).
 
 
Neighbor
 
(1,3)
:
 
‚óè
 
Still
 
{D1,
 
D2}
.
 
 
‚óè
 
g
 
=
 
4
.
 
 
‚óè
 
h
 
=
 
Manhattan((1,3),
 
D1)
 
+
 
Manhattan((1,3),
 
D2)
 
 
=
 
2
 
+
 
4
 
=
 
6.
 
 
‚óè
 
f
 
=
 
4
 
+
 
6
 
=
 
10
.
 
 
Open:
 
{(0,4;
 
{D2}):
 
f=8,
 
(1,3;
 
{D1,
 
D2}):
 
f=10,
 
(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
 
Step
 
5
 
 
22
 

 
Pick
 
(0,4;
 
{D2})
 
(f=8).
 
 
Pacman
 
is
 
now
 
at
 
D1
 
(already
 
eaten
 
D1).
 
 
Open
 
=
 
{(1,3;
 
{D1,
 
D2}):
 
f=10,
 
(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
Still
 
has
 
D2
 
to
 
eat
 
‚Üí
 
expand
 
neighbors:
 
‚óè
 
(0,3)
 
(Closed),
 
(0,5)
 
(out
 
of
 
bounds),
 
(1,4)
 
(down).
 
 
Neighbor
 
(1,4)
:
 
‚óè
 
Remaining
 
{D2}
.
 
 
‚óè
 
g
 
=
 
5
.
 
 
‚óè
 
h
 
=
 
Manhattan((1,4),
 
D2)
 
=
 
3.
 
 
‚óè
 
f
 
=
 
5
 
+
 
3
 
=
 
8
.
 
 
‚Üí
 
(1,4;
 
{D2})
 
added.
 
 
Open:
 
{(1,4;
 
{D2}):
 
f=8,
 
(1,3;
 
{D1,
 
D2}):
 
f=10,
 
(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
 
Step
 
6
 
23
 
 
 
Pick
 
(1,4;
 
{D2})
 
(f=8).
 
 
Open
 
=
 
{(1,3;
 
{D1,
 
D2}):
 
f=10,
 
(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
Expand
 
(1,4)
:
 
‚óè
 
Neighbors:
 
(1,3)
 
(left),
 
(2,4)
 
(down),
 
(0,4)
 
(Closed).
 
 
Neighbor
 
(1,3)
:
 
‚óè
 
Remaining
 
{D2}
.
 
 
‚óè
 
g
 
=
 
6
.
 
 
‚óè
 
h
 
=
 
Manhattan((1,3),
 
D2)
 
=
 
4.
 
 
‚óè
 
f
 
=
 
6
 
+
 
4
 
=
 
10
.
 
 
‚Üí
 
(1,3;
 
{D2})
.
 
 
Neighbor
 
(2,4)
:
 
24
 

 
‚óè
 
Remaining
 
{D2}
.
 
 
‚óè
 
g
 
=
 
6
.
 
 
‚óè
 
h
 
=
 
Manhattan((2,4),
 
D2)
 
=
 
2.
 
 
‚óè
 
f
 
=
 
6
 
+
 
2
 
=
 
8
.
 
 
‚Üí
 
(2,4;
 
{D2})
.
 
 
Open:
 
{(2,4;
 
{D2}):
 
f=8,
 
(1,3;
 
{D1,
 
D2}):
 
f=10,
 
(1,3;
 
{D2}):
 
f=10,
 
(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
 
Step
 
7
 
 
Pick
 
(2,4;
 
{D2})
 
(f=8).
 
 
Open
 
=
 
{(1,3;
 
{D1,
 
D2}):
 
f=10,
 
(1,3;
 
{D2}):
 
f=10,
 
(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
Expand
 
(2,4)
:
 
25
 

 
‚óè
 
Neighbors:
 
(2,3)
 
(left),
 
(3,4)
 
(down),
 
(1,4)
 
(Closed).
 
 
Neighbor
 
(2,3)
:
 
‚óè
 
Remaining
 
{D2}
.
 
 
‚óè
 
g
 
=
 
7
.
 
 
‚óè
 
h
 
=
 
Manhattan((2,3),
 
D2)
 
=
 
3.
 
 
‚óè
 
f
 
=
 
7
 
+
 
3
 
=
 
10
.
 
 
Neighbor
 
(3,4)
:
 
‚óè
 
Remaining
 
{D2}
.
 
 
‚óè
 
g
 
=
 
7
.
 
 
‚óè
 
h
 
=
 
Manhattan((3,4),
 
D2)
 
=
 
1.
 
 
‚óè
 
f
 
=
 
7
 
+
 
1
 
=
 
8
.
 
 
‚Üí
 
(3,4;
 
{D2})
.
 
 
Open:
 
{(3,4;
 
{D2}):
 
f=8,
 
(1,3;
 
{D1,
 
D2}):
 
f=10,
 
(1,3;
 
{D2}):
 
f=10,
 
(2,3;
 
{D2}):
 
f=10,
 
(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
 
Step
 
8
 
26
 
 
 
Pick
 
(3,4;
 
{D2})
 
(f=8).
 
 
Open
 
=
 
{(1,3;
 
{D1,
 
D2}):
 
f=10,
 
(1,3;
 
{D2}):
 
f=10,
 
(2,3;
 
{D2}):
 
f=10,
 
(1,1):
 
f=12,
 
(1,0):
 
f=13}
.
 
Expand
 
(3,4)
:
 
‚óè
 
Neighbors:
 
(3,3)
 
(left),
 
(4,4)
 
(down
 
‚Üí
 
D2
!),
 
(2,4)
 
(Closed).
 
 
Neighbor
 
(3,3)
:
 
‚óè
 
Remaining
 
{D2}
.
 
 
‚óè
 
g
 
=
 
8
.
 
 
‚óè
 
h
 
=
 
Manhattan((3,3),
 
D2)
 
=
 
2.
 
 
‚óè
 
f
 
=
 
8
 
+
 
2
 
=
 
10
.
 
 
Neighbor
 
(4,4)
 
(D2):
 
27
 

 
‚óè
 
Pacman
 
reaches
 
D2
 
‚Üí
 
eats
 
it.
 
 
‚óè
 
New
 
state:
 
(4,4;
 
remainingGoals
 
=
 
‚àÖ
)
.
 
 
‚óè
 
g
 
=
 
8
 
(8
 
steps
 
total).
 
 
‚óè
 
h
 
=
 
0
.
 
 
‚óè
 
f
 
=
 
8
 
+
 
0
 
=
 
8
.
 
 
This
 
is
 
the
 
goal
 
state
 
‚Äî
 
all
 
dots
 
eaten.
 
 
2.3
 
Evaluation
 
&
 
Description
 
 
Heuristic
 
used:
 
The
 
total
 
Manhattan
 
distance
 
from
 
Pac-Man
 
to
 
all
 
uneaten
 
Dots.
 
Meaning:
 
Estimates
 
the
 
total
 
number
 
of
 
steps
 
required
 
to
 
eat
 
all
 
the
 
Dots.
 
Advantages:
 
‚óè
 
Easy
 
to
 
compute
 
‚óè
 
Provides
 
good
 
guidance,
 
helping
 
reduce
 
the
 
number
 
of
 
explored
 
states
 
Disadvantages:
 
‚óè
 
May
 
overestimate
 
the
 
actual
 
cost
 
‚óè
 
Not
 
completely
 
admissible,
 
but
 
still
 
effective
 
on
 
small
 
maps
 
Experiment
 
&
 
Evaluation
 
 
Setup:
 
28
 
 
‚óè
 
Map:
 
5√ó5,
 
no
 
walls
 
‚óè
 
Start:
 
(0,0)
 
‚óè
 
Dots:
 
(4,0),
 
(2,2),
 
(4,4)
 
‚óè
 
Heuristic:
 
total
 
Manhattan
 
distance
 
‚óè
 
Baseline:
 
BFS
 
(absolutely
 
optimal
 
path)
 
 
 
Results:
 
‚óè
 
A*
 
successfully
 
found
 
the
 
correct
 
path
 
that
 
eats
 
all
 
Dots
 
‚óè
 
Cost
 
identical
 
to
 
BFS
 
‚Üí
 
algorithm
 
correctness
 
conÔ¨Årmed
 
‚óè
 
Processing
 
time:
 
0.0005s
 
‚Äì
 
0.0011s
 
‚Üí
 
Faster
 
than
 
BFS,
 
as
 
the
 
heuristic
 
reduces
 
the
 
number
 
of
 
expanded
 
states
 
Detailed
 
Explanation
 
of
 
BFS
 
in
 
the
 
Multi-Goal
 
Pacman
 
Problem
 
üü¢
 
Objective
 
Pacman
 
must
 
find
 
the
 
shortest
 
path
 
that
 
allows
 
him
 
to
 
eat
 
all
 
Dots
 
(food
 
points)
 
on
 
the
 
grid.
 
 
The
 
algorithm
 
must
 
ensure
 
that:
 
‚óè
 
All
 
reachable
 
goals
 
are
 
visited.
 
 
‚óè
 
The
 
total
 
path
 
cost
 
(number
 
of
 
steps)
 
is
 
minimized.
 
 
 
 
State
 
Representation
 
Each
 
state
 
is
 
represented
 
as:
 
state=(currentPosition,remainingGoals)state
 
=
 
(currentPosition,
 
29
 

 
remainingGoals)state=(currentPosition,remainingGoals)
 
‚óè
 
currentPosition
:
 
Pacman‚Äôs
 
current
 
coordinates
 
(x,
 
y)
 
 
‚óè
 
remainingGoals
:
 
a
 
set
 
(or
 
bitmask)
 
containing
 
all
 
uncollected
 
Dots
 
 
Example:
 
state
 
=
 
((0,0),
 
{(0,4),
 
(4,4)})
 
 
means
 
Pacman
 
is
 
at
 
(0,0)
 
and
 
still
 
needs
 
to
 
eat
 
two
 
Dots
 
at
 
(0,4)
 
and
 
(4,4).
 
 
 
Algorithm
 
Steps
 
(Breadth-First
 
Search)
 
1.
 
Initialization
 
 
‚óã
 
Create
 
a
 
queue
 
(FIFO)
 
called
 
Open
 
and
 
insert
 
the
 
start
 
state.
 
 
‚óã
 
Create
 
an
 
empty
 
set
 
Closed
 
to
 
store
 
visited
 
states.
 
 
‚óã
 
Each
 
state
 
also
 
keeps
 
track
 
of
 
its
 
parent
 
for
 
path
 
reconstruction.
 
 
Open
 
=
 
[
 
(startPosition,
 
goalSet)
 
]
 
Closed
 
=
 
‚àÖ
 
parent
 
=
 
{}
 
2.
 
 
3.
 
Loop
 
until
 
Open
 
is
 
empty
 
 
‚óã
 
Pop
 
the
 
first
 
element
 
(FIFO)
 
from
 
Open
.
 
 
‚óã
 
If
 
this
 
state
 
is
 
already
 
in
 
Closed
,
 
skip
 
it.
 
 
30
 
 
‚óã
 
Add
 
it
 
to
 
Closed
.
 
 
4.
 
Goal
 
Check
 
 
‚óã
 
If
 
remainingGoals
 
is
 
empty
 
(
‚àÖ
),
 
Pacman
 
has
 
eaten
 
all
 
Dots
 
‚Üí
 
terminate
 
and
 
reconstruct
 
the
 
path.
 
 
5.
 
Expand
 
Neighbors
 
 
‚óã
 
For
 
each
 
valid
 
neighbor
 
(up,
 
down,
 
left,
 
right):
 
 
‚ñ†
 
If
 
it
 
is
 
not
 
a
 
wall
 
and
 
inside
 
the
 
map:
 
 
‚ñ†
 
Compute
 
new
 
state:
 
 
‚ñ†
 
newPosition
 
=
 
neighbor
 
cell
 
 
‚ñ†
 
newGoals
 
=
 
remainingGoals
 
-
 
{neighbor}
 
if
 
neighbor
 
is
 
a
 
Dot.
 
 
‚ñ†
 
If
 
newState
 
has
 
not
 
been
 
visited
,
 
push
 
it
 
into
 
Open
.
 
 
6.
 
Continue
 
 
‚óã
 
Repeat
 
the
 
process
 
until
 
all
 
possible
 
states
 
are
 
expanded
 
or
 
a
 
goal
 
state
 
is
 
reached.
 
 
7.
 
Output
 
 
‚óã
 
If
 
a
 
goal
 
state
 
is
 
found
 
‚Üí
 
return
 
the
 
reconstructed
 
shortest
 
path.
 
 
‚óã
 
If
 
Open
 
becomes
 
empty
 
‚Üí
 
no
 
solution
 
exists
 
(unreachable
 
goal).
 
 
31
 
 
 
 
import
 
matplotlib.pyplot
 
as
 
plt
 
 
#
 
Define
 
the
 
maze
 
maze
 
=
 
[
 
    
['P',
 
'.',
 
'.',
 
'.',
 
'.'],
 
    
['#',
 
'#',
 
'.',
 
'#',
 
'.'],
 
    
['.',
 
'.',
 
'.',
 
'.',
 
'.'],
 
    
['.',
 
'#',
 
'.',
 
'#',
 
'‚Ä¢'],
 
    
['.',
 
'.',
 
'.',
 
'.',
 
'.']
 
]
 
 
#
 
The
 
path
 
found
 
by
 
BFS
 
path
 
=
 
[(0,
 
0),
 
(0,
 
1),
 
(0,
 
2),
 
(1,
 
2),
 
(2,
 
2),
 
(2,
 
3),
 
(2,
 
4),
 
(3,
 
4)]
 
 
#
 
Draw
 
the
 
grid
 
fig,
 
ax
 
=
 
plt.subplots(figsize=(6,
 
6))
 
for
 
i
 
in
 
range(len(maze)):
 
    
for
 
j
 
in
 
range(len(maze[0])):
 
        
cell
 
=
 
maze[i][j]
 
        
if
 
cell
 
==
 
'#':
 
            
color
 
=
 
'black'
   
#
 
wall
 
        
elif
 
cell
 
==
 
'P':
 
            
color
 
=
 
'limegreen'
  
#
 
Pacman
 
        
elif
 
cell
 
==
 
'‚Ä¢':
 
            
color
 
=
 
'red'
  
#
 
goal
 
(dot)
 
        
else:
 
            
color
 
=
 
'white'
  
#
 
empty
 
space
 
        
rect
 
=
 
plt.Rectangle((j,
 
i),
 
1,
 
1,
 
facecolor=color,
 
edgecolor='gray')
 
        
ax.add_patch(rect)
 
 
#
 
Draw
 
the
 
actual
 
BFS
 
path
 
for
 
(x1,
 
y1),
 
(x2,
 
y2)
 
in
 
zip(path[:-1],
 
path[1:]):
 
    
plt.plot([y1
 
+
 
0.5,
 
y2
 
+
 
0.5],
 
[x1
 
+
 
0.5,
 
x2
 
+
 
0.5],
 
color='blue',
 
linewidth=3)
 
 
32
 
 
#
 
Visualization
 
settings
 
ax.set_xlim(0,
 
len(maze[0]))
 
ax.set_ylim(len(maze),
 
0)
 
ax.set_xticks(range(len(maze[0])
 
+
 
1))
 
ax.set_yticks(range(len(maze)
 
+
 
1))
 
ax.set_xticklabels([])
 
ax.set_yticklabels([])
 
ax.grid(True)
 
 
plt.title("
‚úÖ
 
BFS
 
Path
 
in
 
Pacman
 
Maze
 
(Walls
 
Included)")
 
plt.show()
 
 
33
 
 
 
 
 
Comparison
 
between
 
BFS
 
and
 
A
 
(Manhattan)
*
 
 
Criteria
 
BFS
 
A
 
(Manhattan)
*
 
Path
 
length
 
9
 
cells
 
(8
 
steps)
 
‚Äì
 
optimal
 
9
 
cells
 
(8
 
steps)
 
‚Äì
 
optimal
 
Path
 
optimality
 
Locally
 
optimal
 
(shortest
 
path)
 
Optimal
 
if
 
heuristic
 
is
 
admissible
 
34
 

 
Time
 
complexity
 
O(b^d)
 
‚Äì
 
explores
 
all
 
nodes
 
O(b^d)
 
‚Äì
 
smaller
 
due
 
to
 
heuristic
 
Memory
 
usage
 
High
 
(queue
 
+
 
visited)
 
Lower,
 
heuristic-guided
 
Number
 
of
 
expanded
 
nodes
 
(5√ó5)
 
~23
 
cells
 
~10
 
cells
 
Execution
 
speed
 
Slower
 
(~2.3√ó
 
more
 
nodes)
 
Faster,
 
more
 
resource-efficient
 
Advantages
 
Simple,
 
accurate
 
Efficient,
 
goal-directed
 
Disadvantages
 
Time
 
and
 
memory
 
consuming
 
Requires
 
suitable
 
heuristic
 
selection
 
 
 
Algorithm
 
Search
 
Space
 
Heuristic
 
Function
 
Time
 
Complexity
 
Space
 
Comple 
xity
 
Main
 
Character 
istics
 
General
 
Remarks
 
BFS
 
‚Äì
 
Multi
 
Goal
 
O(N√óM√ó2 
k)O(N
 
\times
 
M
 
\times
 
2^k)O(N√ó 
M√ó2k)
 
None
 
O(N√óM√ó2k) 
O(N
 
\times
 
M
 
\times
 
2^k)O(N√óM 
√ó2k)
 
O(N√óM√ó 
2k)O(N
 
\times
 
M
 
\times
 
2^k)O(N 
√óM√ó2k)
 
Each
 
state
 
is
 
represente 
d
 
as
 
(current
 
position,
 
remaining
 
set
 
of
 
Dots).
 
BFS
 
must
 
explore
 
all
 
possible
 
state
 
combinatio 
ns.
 
Extremely
 
time-
 
and
 
memory-c 
onsuming;
 
impractical
 
for
 
large
 
maps
 
or
 
many
 
Dots.
 
A
 
‚Äì
 
Multi
 
Goal
 
(weak
 
heuristic)
*
 
O(N√óM√ó2 
k)O(N
 
\times
 
M
 
\times
 
2^k)O(N√ó
Yes,
 
but
 
weak
 
(e.g.,
 
only
 
distance
 
to
 
the
 
nearest
 
‚âà
 
O(N√óM√ó2k) 
O(N
 
\times
 
M
 
\times
 
2^k)O(N√óM 
√ó2k)
 
(almost
 
‚âà
 
O(N√óM√ó 
2k)O(N
 
\times
 
M
 
\times
 
2^k)O(N
The
 
heuristic
 
provides
 
poor
 
guidance,
 
so
 
few
 
Inefficient
 
‚Äî
 
performs
 
nearly
 
like
 
BFS.
 
35
 
 
M√ó2k)
 
Dot)
 
same
 
as
 
BFS)
 
√óM√ó2k)
 
(almost
 
same
 
as
 
BFS)
 
nodes
 
are
 
pruned.
 
A
 
‚Äì
 
Multi
 
Goal
 
(strong
 
heuristic)
*
 
O(N√óM√ó2 
k)O(N
 
\times
 
M
 
\times
 
2^k)O(N√ó 
M√ó2k)
 
Yes
 
(e.g.,
 
total
 
Manhattan
 
distance,
 
MST,
 
Tu·∫•n
 
Anh‚Äôs
 
heuristic)
 
‚â™
 
O(N√óM√ó2k) 
O(N
 
\times
 
M
 
\times
 
2^k)O(N√óM 
√ó2k)
 
(significantl 
y
 
reduced
 
in
 
practice)
 
‚â™
 
O(N√óM√ó 
2k)O(N
 
\times
 
M
 
\times
 
2^k)O(N 
√óM√ó2k)
 
The
 
heuristic
 
effectively
 
directs
 
the
 
search,
 
expanding
 
only
 
promising
 
areas
 
‚Üí
 
much
 
faster
 
solution.
 
Optimal
 
choice
 
for
 
large
 
maps
 
or
 
many
 
Dots.
 
 
 
 
3
 
Discuss
 
3.1
 
Limitations
 
of
 
the
 
Current
 
Model
 
Small
 
map
 
size
 
(5√ó5):
 
‚óè
 
Limits
 
the
 
ability
 
to
 
evaluate
 
the
 
algorithm‚Äôs
 
performance
 
in
 
more
 
complex
 
environments.
 
‚óè
 
Few
 
Dots
 
and
 
walls
 
‚Üí
 
does
 
not
 
fully
 
reÔ¨Çect
 
the
 
challenges
 
of
 
real-world
 
problems.
 
Simple
 
heuristic
 
(total
 
Manhattan
 
distance):
 
‚óè
 
Not
 
always
 
admissible
 
(may
 
overestimate
 
the
 
true
 
cost).
 
‚óè
 
Does
 
not
 
account
 
for
 
relationships
 
between
 
Dots
 
(e.g.,
 
optimal
 
paths
 
visiting
 
nearby
 
Dots).
 
No
 
dynamic
 
elements
 
(Ghosts
 
/
 
other
 
agents):
 
‚óè
 
Static
 
environment
 
with
 
no
 
risks
 
or
 
changes
 
during
 
movement.
 
‚óè
 
Cannot
 
evaluate
 
the
 
algorithm‚Äôs
 
ability
 
to
 
react
 
or
 
avoid
 
opponents.
 
36
 
 
3.2
 
Future
 
Development
 
Directions
 
Expand
 
map
 
scale:
 
‚óè
 
Increase
 
size
 
(e.g.,
 
10√ó10,
 
20√ó20)
 
to
 
test
 
scalability.
 
‚óè
 
Add
 
more
 
walls
 
and
 
obstacles
 
to
 
raise
 
complexity.
 
Integrate
 
multiple
 
agents:
 
‚óè
 
Introduce
 
Ghosts
 
(chasers)
 
or
 
multiple
 
cooperating
 
Pac-Men.
 
‚óè
 
Explore
 
cooperative
 
or
 
avoidance
 
strategies
 
(multi-agent
 
pathfinding).
 
Improve
 
heuristic:
 
‚óè
 
Use
 
advanced
 
heuristics
 
(e.g.,
 
Minimum
 
Spanning
 
Tree
 
among
 
Dots,
 
or
 
Nearest
 
Neighbor
 
Heuristic)
 
for
 
more
 
accurate
 
estimates.
 
‚óè
 
Combine
 
machine
 
learning‚Äìbased
 
heuristics
 
for
 
complex
 
environments.
 
 
 
 
 
4
 
Conclusion
 
 
The
 
application
 
of
 
the
 
A*
 
algorithm
 
in
 
the
 
Pac-Man
 
game
 
demonstrates
 
its
 
effectiveness
 
in
 
finding
 
optimal
 
paths
 
and
 
enabling
 
intelligent
 
movement
 
control.
 
A*
 
maintains
 
a
 
balance
 
between
 
processing
 
speed
 
and
 
accuracy,
 
allowing
 
characters
 
to
 
find
 
the
 
shortest
 
route
 
in
 
real
 
time.
 
This
 
proves
 
that
 
A*
 
is
 
a
 
suitable
 
choice
 
for
 
AI
 
systems
 
in
 
games,
 
contributing
 
to
 
enhanced
 
strategy,
 
difficulty,
 
and
 
overall
 
player
 
experience.
 
 
37
 